{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runing\n"
     ]
    }
   ],
   "source": [
    "print('runing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "from partglot.utils.predict import get_loaded_model\n",
    "import numpy as np\n",
    "from src.helper.visualization import visualize_pointclouds_parts_partglot\n",
    "\n",
    "import pymeshlab as pm\n",
    "import torch\n",
    "from partglot.utils.neural_utils import tokenizing\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def sort_arrays(arrays):\n",
    "    ref_array = arrays[0]\n",
    "    sorted_indices = ref_array.argsort()\n",
    "    out = []\n",
    "    for a in arrays:\n",
    "        out.append(a[sorted_indices])\n",
    "    return out\n",
    "\n",
    "def random_sample_array(arr: np.array, size: int = 1, with_replacement:bool=True) -> np.array:\n",
    "    if with_replacement:\n",
    "        while len(arr) < size:\n",
    "            arr = np.concatenate([arr, arr])\n",
    "    return arr[np.random.choice(len(arr), size=size, replace=False)]\n",
    "\n",
    "def cluster_supsegs(sorted_labels, sorted_pc, sup_seg_size=512):\n",
    "    sup_segs, labels = [], []\n",
    "    for lbl in np.unique(sorted_labels):\n",
    "        indices = np.where(sorted_labels==lbl)[0]\n",
    "        tmp_pc = sorted_pc[indices]\n",
    "        tmp_lbl = sorted_labels[indices]\n",
    "        sup_segs.append(random_sample_array(tmp_pc, sup_seg_size))\n",
    "        # labels.append(random_sample_array(tmp_lbl, sup_seg_size))\n",
    "        labels.append(lbl)\n",
    "    return np.array(sup_segs), np.array(labels)\n",
    "\n",
    "\n",
    "def get_attn_mask_objects(pc, pc2label):\n",
    "    \"\"\"\n",
    "    Returns ordered point cloud and mask indices in our format.\n",
    "    \"\"\"\n",
    "    stacked_pc = np.vstack(np.vstack(pc))\n",
    "    \n",
    "    arg_sort = pc2label.argsort()\n",
    "    \n",
    "    out_pc2label, out_pg_pc = pc2label[arg_sort], np.vstack(stacked_pc)[arg_sort]\n",
    "\n",
    "    mask = {}\n",
    "    for i, pn in enumerate(part_names):\n",
    "        tmp = np.where(out_pc2label == i)[0]\n",
    "        mask[pn] = [tmp.min(), tmp.max()]\n",
    "    \n",
    "    return {\"mask_vertices\": mask}, out_pg_pc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_974786/3776868927.py:74: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  visualize_pointclouds_parts_partglot(np.array(out))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a4043f1dd048399563d6c5be134c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_idx = 0\n",
    "run_gt = True\n",
    "\n",
    "np.random.seed(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "part_names = [\"back\", \"seat\", \"leg\", \"arm\"]\n",
    "\n",
    "part_semantic_groups = {\n",
    "    \"back\": [\"back\"],\n",
    "    \"seat\": [\"seat\"],\n",
    "    \"leg\": [\"leg\", \"wheel\", \"base\"],\n",
    "    \"arm\": [\"arm\"],\n",
    "}\n",
    "\n",
    "model_dir = \"/home/bellatini/DL3D-Practical/models/pn_agnostic.ckpt\"\n",
    "# data_dir = \"/home/bellatini/DL3D-Practical/data/partglot\"\n",
    "data_dir = \"/home/bellatini/DL3D-Practical/data/partglot_100\"\n",
    "\n",
    "partglot, partglot_dm = get_loaded_model(data_dir=data_dir, model_path=model_dir)\n",
    "sup_segs2label, pc2label = partglot.get_attn_maps()[sample_idx]\n",
    "segs, masks = partglot_dm.h5_data['data'][sample_idx], partglot_dm.h5_data['mask'][sample_idx]\n",
    "\n",
    "partglot.to(device)\n",
    "\n",
    "\n",
    "batch_data = torch.from_numpy(partglot_dm.h5_data['data'][sample_idx:sample_idx+1]).unsqueeze(dim=1).float().to(device)\n",
    "mask_data = torch.from_numpy(partglot_dm.h5_data['mask'][sample_idx:sample_idx+1]).unsqueeze(dim=1).float().to(device)\n",
    "\n",
    "pc = np.vstack((np.vstack(np.vstack(batch_data.cpu().numpy()))))\n",
    "\n",
    "kmeans = KMeans(n_clusters=25, random_state=1).fit(pc)\n",
    "pc2sup_segs_kmeans = kmeans.labels_\n",
    "np.unique(pc2sup_segs_kmeans, return_counts=True)\n",
    "\n",
    "sorted_labels, sorted_pc = sort_arrays((kmeans.labels_, pc))\n",
    "\n",
    "super_segs, pc2sup_segs = cluster_supsegs(sorted_labels, sorted_pc)\n",
    "\n",
    "custom_ssegs_batch = torch.from_numpy(np.array([[super_segs]])).float().to(device)\n",
    "custom_mask_batch = torch.from_numpy(np.array([[np.ones(custom_ssegs_batch.shape[2])]])).float().to(device)\n",
    "custom_ssegs_batch.shape, custom_mask_batch.shape\n",
    "\n",
    "\n",
    "if run_gt:\n",
    "    final_ssegs_batch = batch_data\n",
    "    final_mask_batch = mask_data \n",
    "    super_segs = batch_data[0][0].cpu().numpy() # gt_super_segs / super_segs\n",
    "else:\n",
    "    final_ssegs_batch = custom_ssegs_batch \n",
    "    final_mask_batch = custom_mask_batch \n",
    "    \n",
    "attn_maps = []\n",
    "for pn in part_names:\n",
    "    text_embeddings = tokenizing(partglot_dm.word2int, f\"chair with a {pn}\").to(device)[None].expand(\n",
    "        1, -1\n",
    "    )\n",
    "    tmp = partglot.forward(\n",
    "        final_ssegs_batch, # custom_ssegs_batch / batch_data\n",
    "        final_mask_batch, # custom_mask_batch / mask_data\n",
    "        text_embeddings, True)\n",
    "    attn_maps.append(tmp)\n",
    "    \n",
    "\n",
    "attn_maps_concat = torch.cat(attn_maps).max(0)[1].cpu().numpy()\n",
    "sup_segs2label = np.squeeze(attn_maps_concat)\n",
    "sup_segs2label\n",
    "\n",
    "# CHANGE THIS TO TWEAT RUN!\n",
    "K, n_points, coord = super_segs.shape\n",
    "\n",
    "sup_segs2label_sorted=[] # pc2sup_segs: is actually pc2label\n",
    "for lbl in sup_segs2label:\n",
    "    tmp = np.ones(n_points) * lbl\n",
    "    sup_segs2label_sorted.append(tmp)\n",
    "    \n",
    "sup_segs2label_sorted = np.concatenate(sup_segs2label_sorted).astype(int)\n",
    "\n",
    "assign_ft = lambda x: sup_segs2label[x]\n",
    "\n",
    "pc2label_sorted = assign_ft(pc2sup_segs.astype(int))\n",
    "\n",
    "import numpy as np\n",
    "pc2label_prefinal = []\n",
    "for lbl in sup_segs2label:\n",
    "    tmp = np.ones(512)*lbl\n",
    "    pc2label_prefinal.append(tmp)\n",
    "pc2label_prefinal = np.concatenate(pc2label_prefinal)\n",
    "\n",
    "pc_final = np.vstack(super_segs)\n",
    "\n",
    "# final_mask, final_pc = get_attn_mask_objects(super_segs, pc2label)\n",
    "final_mask, final_pc = get_attn_mask_objects(pc_final, pc2label_prefinal) # pc2sup_segs: is actually pc2label\n",
    "\n",
    "out = []\n",
    "for s,f in final_mask['mask_vertices'].values():\n",
    "    tmp = final_pc[s:f].astype(float)\n",
    "    out.append(tmp)\n",
    "    \n",
    "visualize_pointclouds_parts_partglot(np.array(out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_974786/3618547245.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  visualize_pointclouds_parts_partglot(np.array(out))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a87466f056486b8418359e95c433e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_974786/3618547245.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  visualize_pointclouds_parts_partglot(np.array(out))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c58aa02d7b48b08d9d17e4f73cf2ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sup_segs2label_sorted[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25600,), (25600, 3))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sup_segs2label_sorted.shape, np.vstack(super_segs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0, 1, 2, 3]), array([6144, 6656, 6144, 6656])),\n",
       " (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "         17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "         34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "        dtype=int32),\n",
       "  array([18022,   414,   152,   178,   132,   124,   202,   201,   142,\n",
       "           105,   131,   125,   125,   105,    99,   100,   135,   138,\n",
       "           111,   179,   124,   160,   113,   176,   163,   149,    96,\n",
       "           191,    85,   131,   213,   145,   211,   170,    77,    82,\n",
       "           235,   259,    91,   234,   398,   152,   139,   118,   126,\n",
       "           127,    97,   139,   128,   151])),\n",
       " (50, 512, 3))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(sup_segs2label_sorted, return_counts=True), np.unique(pc2sup_segs_kmeans, return_counts=True), super_segs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_974786/3618547245.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  visualize_pointclouds_parts_partglot(np.array(out))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd9943b512d4a1e8ddb704718a5cd0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_970082/1133928863.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.array(out)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([array([[-0.07908174,  0.64580595,  0.36080492],\n",
       "              [-0.16577069, -0.10363343,  0.12228566],\n",
       "              [-0.18233299, -0.13928761,  0.15949082],\n",
       "              ...,\n",
       "              [ 0.13689284,  0.55354083,  0.32345203],\n",
       "              [ 0.11216941,  0.64667374,  0.35172057],\n",
       "              [ 0.13975477,  0.65062511,  0.35526568]]),\n",
       "       array([[ 0.18890621, -0.39108256, -0.22447015],\n",
       "              [ 0.18783529, -0.29047167, -0.214518  ],\n",
       "              [ 0.18397629, -0.33517325, -0.25515747],\n",
       "              ...,\n",
       "              [ 0.14968847, -0.5149582 ,  0.18857178],\n",
       "              [ 0.23388477, -0.49047479,  0.16833512],\n",
       "              [ 0.26789564, -0.5133149 ,  0.0116857 ]]),\n",
       "       array([[ 0.25526619, -0.82515508,  0.19333552],\n",
       "              [ 0.22683148, -0.75497305,  0.19867164],\n",
       "              [ 0.26904041, -0.80004388,  0.2088269 ],\n",
       "              ...,\n",
       "              [ 0.2166393 , -0.72088832, -0.29215953],\n",
       "              [ 0.22620369, -0.72927099, -0.29806805],\n",
       "              [ 0.13513875, -0.49695569, -0.23789355]]),\n",
       "       array([[ 0.25225654,  0.52130252,  0.25408241],\n",
       "              [ 0.24204589,  0.54382873,  0.22930358],\n",
       "              [ 0.26012224,  0.5752731 ,  0.28004295],\n",
       "              ...,\n",
       "              [ 0.15498766,  0.15977544,  0.18997505],\n",
       "              [ 0.2448709 ,  0.12988205,  0.17208333],\n",
       "              [ 0.1763137 , -0.202084  , -0.20414117]])], dtype=object)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [132], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[39m.\u001b[39;49marray(out, dtype\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = []\n",
    "# f = 0\n",
    "# for i in range(50):\n",
    "#     s, f = i*512, f + 512\n",
    "#     out.append(y[s:f])\n",
    "# out = np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_970082/2765739158.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  visualize_pointclouds_parts_partglot(np.array(out)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582ea612a40348089b37f4b43b0076fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25600,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 2, 3, 1, 0, 2, 1, 3, 3, 2, 1, 2, 1, 3, 2, 0, 3, 0, 0, 2,\n",
       "         2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_maps_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1729, 3)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(final_pc, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12800, 3)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(super_segs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6400.0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc2label.shape[0] /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12800, 3)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "for s,f in final_mask['mask_vertices'].values():\n",
    "    tmp = final_pc[s:f]\n",
    "    out.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc2label_ref = np.load(\"/home/bellatini/DL3D-Practical/Baselines/PartGlot/logs/pre_trained/pn_agnostic/12-12_14-37-13/pred_label/final/0_pc_label.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2691,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc2label_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2691,), array([0, 1, 2, 3]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc2label_ref.shape, np.unique(pc2label_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cat(attn_maps).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f85439aa3d49cb9e00af694d6138b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_pointclouds_parts_partglot(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aaca0088a3f41df940d6655e6da28a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_pointclouds_parts_partglot(segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc2label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dl3d')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5edac632bc030e698bde792f49d6429b3d15e7fbac06b4787d1057cf5bdd41d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
