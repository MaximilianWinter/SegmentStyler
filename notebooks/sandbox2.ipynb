{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "runing\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print('runing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from partglot.utils.predict import get_loaded_model\n",
    "import numpy as np\n",
    "from src.helper.visualization import visualize_pointclouds_parts_partglot\n",
    "from src.helper.visualization import get_rnd_color\n",
    "\n",
    "import pymeshlab as pm\n",
    "import torch\n",
    "from partglot.utils.neural_utils import tokenizing\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "part_names = [\"back\", \"seat\", \"leg\", \"arm\"]\n",
    "sseg_cmap = [get_rnd_color() for i in range(1000)]\n",
    "\n",
    "part_semantic_groups = {\n",
    "    \"back\": [\"back\"],\n",
    "    \"seat\": [\"seat\"],\n",
    "    \"leg\": [\"leg\", \"wheel\", \"base\"],\n",
    "    \"arm\": [\"arm\"],\n",
    "}\n",
    "\n",
    "def sort_arrays(arrays):\n",
    "    ref_array = arrays[0]\n",
    "    sorted_indices = ref_array.argsort()\n",
    "    out = []\n",
    "    for a in arrays:\n",
    "        out.append(a[sorted_indices])\n",
    "    return out\n",
    "\n",
    "def random_sample_array(arr: np.array, size: int = 1, with_replacement:bool=True) -> np.array:\n",
    "    if with_replacement:\n",
    "        while len(arr) < size:\n",
    "            arr = np.concatenate([arr, arr])\n",
    "    return arr[np.random.choice(len(arr), size=size, replace=False)]\n",
    "\n",
    "def cluster_supsegs(sorted_labels, sorted_pc, sup_seg_size=512):\n",
    "    sup_segs, labels = [], []\n",
    "    for lbl in np.unique(sorted_labels):\n",
    "        indices = np.where(sorted_labels==lbl)[0]\n",
    "        tmp_pc = sorted_pc[indices]\n",
    "        tmp_lbl = sorted_labels[indices]\n",
    "        sup_segs.append(random_sample_array(tmp_pc, sup_seg_size))\n",
    "        # labels.append(random_sample_array(tmp_lbl, sup_seg_size))\n",
    "        labels.append(lbl)\n",
    "    return np.array(sup_segs), np.array(labels)\n",
    "\n",
    "\n",
    "def get_attn_mask_objects(pc, pc2label):\n",
    "    \"\"\"\n",
    "    Returns ordered point cloud and mask indices in our format.\n",
    "    \"\"\"\n",
    "    stacked_pc = np.vstack(np.vstack(pc))\n",
    "    \n",
    "    arg_sort = pc2label.argsort()\n",
    "    \n",
    "    out_pc2label, out_pg_pc = pc2label[arg_sort], np.vstack(stacked_pc)[arg_sort]\n",
    "\n",
    "    mask = {}\n",
    "    for i, pn in enumerate(part_names):\n",
    "        tmp = np.where(out_pc2label == i)[0]\n",
    "        print(tmp.shape)\n",
    "        if tmp.shape[0] == 0:\n",
    "            continue\n",
    "        mask[pn] = [tmp.min(), tmp.max()]\n",
    "    \n",
    "    return {\"mask_vertices\": mask}, out_pg_pc\n",
    "\n",
    "def vstack2dim(data, dim=2):\n",
    "    if len(data.shape) <= dim:\n",
    "        return data\n",
    "    else:\n",
    "        data = np.vstack(data)\n",
    "        return vstack2dim(data=data, dim=dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write state dict\n",
      "(2560,)\n",
      "(4608,)\n",
      "(4096,)\n",
      "(1536,)\n",
      "use_bsp_ssegs_gt: False\n",
      "unique point percentage: 17.6%\n",
      "unique point percentage (non-zeros): 18.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_982162/1482781462.py:98: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  visualize_pointclouds_parts_partglot(np.array(out), names=list(final_mask['mask_vertices'].keys()), part_colors=label_cmap, opacity=opacity)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a92d7e121f4c368e32a8e45e772341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_idx = 1\n",
    "use_bsp_ssegs_gt = False\n",
    "n_ssseg_custom = 25\n",
    "opacity = 0.25\n",
    "\n",
    "np.random.seed(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "label_cmap = [0xff0000, 0x00ff00, 0x0000ff, 0xff00ff, 0xffff00, 0x00ffff]\n",
    "\n",
    "\n",
    "model_dir = \"/home/bellatini/DL3D-Practical/models/pn_agnostic.ckpt\"\n",
    "# data_dir = \"/home/bellatini/DL3D-Practical/data/partglot\"\n",
    "data_dir = \"/home/bellatini/DL3D-Practical/data/partglot_100\"\n",
    "\n",
    "# LOAD MODEL AND REFERENCE DATASET\n",
    "partglot, partglot_dm = get_loaded_model(data_dir=data_dir, model_path=model_dir)\n",
    "batch_data = torch.from_numpy(partglot_dm.h5_data['data'][sample_idx:sample_idx+1]).unsqueeze(dim=1).float().to(device)\n",
    "mask_data = torch.from_numpy(partglot_dm.h5_data['mask'][sample_idx:sample_idx+1]).unsqueeze(dim=1).float().to(device)\n",
    "\n",
    "# sup_segs2label, pc2label = partglot.get_attn_maps()[sample_idx]\n",
    "# segs, masks = partglot_dm.h5_data['data'][sample_idx], partglot_dm.h5_data['mask'][sample_idx]\n",
    "\n",
    "partglot.to(device)\n",
    "\n",
    "# CLUSTER POINT CLOUD INTO SSEGS (KMEANS)\n",
    "pc = vstack2dim(batch_data.cpu().numpy())\n",
    "kmeans = KMeans(n_clusters=n_ssseg_custom, random_state=1).fit(pc)\n",
    "pc2sup_segs_kmeans = kmeans.labels_\n",
    "# sorted_labels, sorted_pc = sort_arrays((pc2sup_segs_kmeans, pc))\n",
    "# sorted_ssegs, pc2sup_segs = cluster_supsegs(sorted_labels, sorted_pc)\n",
    "sup_segs, pc2sup_segs = cluster_supsegs(pc2sup_segs_kmeans, pc)\n",
    "\n",
    "# SET VARIABLES FOR PREDICTION (REF POINT CLOUDS OR CUSTOM ONES)\n",
    "if use_bsp_ssegs_gt:\n",
    "    final_ssegs_batch = batch_data\n",
    "    final_mask_batch = mask_data \n",
    "    sup_segs = batch_data[0][0].cpu().numpy() # gt_super_segs / super_segs\n",
    "else:\n",
    "    final_ssegs_batch = torch.from_numpy(np.array([[sup_segs]])).float().to(device) \n",
    "    final_mask_batch = torch.from_numpy(np.array([[np.ones(final_ssegs_batch.shape[2])]])).float().to(device) \n",
    "    \n",
    "# GET ATTN MAPS PER SSEG (sseg2label)\n",
    "attn_maps = []\n",
    "for pn in part_names:\n",
    "    text_embeddings = tokenizing(partglot_dm.word2int, f\"chair with a {pn}\").to(device)[None].expand(\n",
    "        1, -1\n",
    "    )\n",
    "    tmp = partglot.forward(\n",
    "        final_ssegs_batch, # custom_ssegs_batch / batch_data\n",
    "        final_mask_batch, # custom_mask_batch / mask_data\n",
    "        text_embeddings, True)\n",
    "    attn_maps.append(tmp)\n",
    "    \n",
    "attn_maps_concat = torch.cat(attn_maps).max(0)[1].cpu().numpy()\n",
    "\n",
    "sup_segs2label = np.squeeze(attn_maps_concat)\n",
    "sup_segs2label\n",
    "\n",
    "# EXPAND ATTN MAPS TO POINT-LEVEL GRANULARITY (pc2label)\n",
    "pc2label=[] # pc2sup_segs: is actually pc2label\n",
    "for lbl in sup_segs2label:\n",
    "    tmp = np.ones(512) * lbl\n",
    "    pc2label.append(tmp)\n",
    "    \n",
    "pc2label = np.concatenate(pc2label).astype(int)\n",
    "\n",
    "assign_ft = lambda x: sup_segs2label[x]\n",
    "\n",
    "# pc2label_sorted = assign_ft(pc2sup_segs.astype(int))\n",
    "# import numpy as np\n",
    "# pc2label_prefinal = []\n",
    "# for lbl in sup_segs2label:\n",
    "#     tmp = np.ones(512)*lbl\n",
    "#     pc2label_prefinal.append(tmp)\n",
    "# pc2label_prefinal = np.concatenate(pc2label_prefinal)\n",
    "\n",
    "# VISUALIZE PART SEGMENTATION LABELS\n",
    "pc_final = vstack2dim(final_ssegs_batch.cpu().numpy())\n",
    "# pc_final = vstack2dim(vstack2dim(sorted_ssegs))\n",
    "\n",
    "# final_mask, final_pc = get_attn_mask_objects(super_segs, pc2label)\n",
    "final_mask, final_pc = get_attn_mask_objects(pc_final, pc2label) # pc2sup_segs: is actually pc2label\n",
    "\n",
    "mask = (pc_final != np.array([0,0,0])).max(axis=1)\n",
    "non_zero_pc = pc_final[mask]\n",
    "\n",
    "unique_point_perc = np.unique(pc_final, axis=0).shape[0] / vstack2dim(pc_final).shape[0]\n",
    "unique_point_perc_non_zero = np.unique(non_zero_pc, axis=0).shape[0] / vstack2dim(non_zero_pc).shape[0]\n",
    "print(\"use_bsp_ssegs_gt:\", use_bsp_ssegs_gt)\n",
    "print(f\"unique point percentage: {unique_point_perc:.1%}\")\n",
    "print(f\"unique point percentage (non-zeros): {unique_point_perc_non_zero:.1%}\")\n",
    "\n",
    "out = []\n",
    "for s,f in final_mask['mask_vertices'].values():\n",
    "    tmp = final_pc[s:f].astype(float)\n",
    "    out.append(tmp)\n",
    "    \n",
    "visualize_pointclouds_parts_partglot(np.array(out), names=list(final_mask['mask_vertices'].keys()), part_colors=label_cmap, opacity=opacity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd8d254a9574aab8a08e78868d6a3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_pointclouds_parts_partglot(sup_segs, opacity=opacity, part_colors=sseg_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06cc977b9e649d289374fc23bd8d4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_pointclouds_parts_partglot(sup_segs, opacity=opacity, part_colors=sseg_cmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pc_final[:, pc_final \u001b[39m!=\u001b[39;49m [\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m]]\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "pc_final[:, pc_final != [0,0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00014960766"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc2label=[] # pc2sup_segs: is actually pc2label\n",
    "for lbl in sup_segs2label:\n",
    "    tmp = np.ones(n_ssseg_custom) * lbl\n",
    "    pc2label.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc2label = np.concatenate(pc2label).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc2label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_ssseg_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 2, 3, 1, 0, 2, 1, 3, 3, 2, 1, 2, 1, 3, 2, 0, 3, 0, 0, 2,\n",
       "         2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_maps_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1729, 3)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(final_pc, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12800, 3)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(sup_segs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6400.0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc2label.shape[0] /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12800, 3)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "for s,f in final_mask['mask_vertices'].values():\n",
    "    tmp = final_pc[s:f]\n",
    "    out.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc2label_ref = np.load(\"/home/bellatini/DL3D-Practical/Baselines/PartGlot/logs/pre_trained/pn_agnostic/12-12_14-37-13/pred_label/final/0_pc_label.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2691,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc2label_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2691,), array([0, 1, 2, 3]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc2label_ref.shape, np.unique(pc2label_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cat(attn_maps).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f85439aa3d49cb9e00af694d6138b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_pointclouds_parts_partglot(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aaca0088a3f41df940d6655e6da28a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_pointclouds_parts_partglot(segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc2label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dl3d')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5edac632bc030e698bde792f49d6429b3d15e7fbac06b4787d1057cf5bdd41d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
